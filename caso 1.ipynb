{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq \n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_KEY')\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIEMPO DE RESPUESTA: 0.6229608058929443\n",
      "\n",
      "('LangSmith es una herramienta de procesamiento de lenguaje natural que '\n",
      " 'utiliza inteligencia artificial para analizar y generar texto en diferentes '\n",
      " 'idiomas. Permite a los desarrolladores crear aplicaciones que pueden '\n",
      " 'entender y responder a preguntas, generar texto, traducir idiomas y mÃ¡s.')\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\")\n",
    "\n",
    "respuesta = llm.predict(\"Â¿Que es LangSmith?, Se breve\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print(\"TIEMPO DE RESPUESTA: \" + str(end - start) + \"\\n\")\n",
    "pprint.pprint(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIEMPO DE RESPUESTA: 2.5899925231933594\n",
      "\n",
      "('LangSmith es una empresa especializada en la enseÃ±anza de idiomas a travÃ©s '\n",
      " 'de clases particulares, cursos grupales y programas de inmersiÃ³n '\n",
      " 'lingÃ¼Ã­stica. Ofrecen servicios de enseÃ±anza de idiomas tanto para adultos '\n",
      " 'como para niÃ±os, adaptÃ¡ndose a las necesidades y objetivos de cada '\n",
      " 'estudiante. AdemÃ¡s, cuentan con un equipo de profesores altamente '\n",
      " 'cualificados y con experiencia en la enseÃ±anza de idiomas.')\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "respuesta = llm.predict(\"Â¿Que es LangSmith?\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"TIEMPO DE RESPUESTA: \" + str(end - start) + \"\\n\")\n",
    "pprint.pprint(respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/1.png\" width=\"500\" height=\"340\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No responde bien a algunas preguntas. Vamos a usar los *Documents Loaders*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader= WebBaseLoader(web_path=\"https://www.langchain.com/langsmith\")\n",
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LangSmith\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Products\\n'\n",
      " '\\n'\n",
      " 'LangChainLangSmithLangServeMethods\\n'\n",
      " '\\n'\n",
      " 'RetrievalAgentsEvaluationResources\\n'\n",
      " '\\n'\n",
      " 'Developer ResourcesTemplatesIntegrationsLangChain QuickstartLangChain.js '\n",
      " 'QuickstartCompany ResourcesBlogCase StudiesUse Case '\n",
      " 'InspirationPartnersLangSmith Trust PortalDocs\\n'\n",
      " '\\n'\n",
      " 'LangChain DocsLangSmith DocsPricingCompany\\n'\n",
      " '\\n'\n",
      " 'AboutCareersSign UpGet your LLM app from prototype to productionAn '\n",
      " 'all-in-one developer platform for every step of the LLM-powered '\n",
      " 'application\\xa0lifecycle, whether youâ€™re building with LangChain or not.Sign '\n",
      " 'upRequest a demo\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'LangSmith is a unified DevOps platform for developing, collaborating, '\n",
      " 'testing, deploying, and monitoring LLM applications.100K+Users signed up\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '200M+Traces logged\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '20K+Monthly active teams\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'The platform for your LLM development lifecycleLLM-apps are powerful, but '\n",
      " 'have peculiar characteristics. The non-determinism, coupled with '\n",
      " 'unpredictable, natural language inputs, make for countless ways the system '\n",
      " 'can fall short. Traditional engineering best practices need to be '\n",
      " 're-imagined for working with LLMs, and LangSmith supports all phases of the '\n",
      " 'development lifecycle.Sign Up\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Develop with greater visibilityUnexpected results happen all the time with '\n",
      " 'LLMs. With full visibility into the entire sequence of calls, you can spot '\n",
      " 'the source of errors and performance bottlenecks in real-time with surgical '\n",
      " 'precision. Debug. Experiment. Observe. Repeat. Until youâ€™re happy with your '\n",
      " 'results.Go to Docs\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Collaborate with teammates to get app behavior just right.Building '\n",
      " 'LLM-powered applications requires a close partnership between\\xa0developers '\n",
      " 'and subject matter experts.Go to Docs\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'TracesEasily share a chain trace with colleagues, clients, or end users, '\n",
      " 'bringing explainability to anyone with the shared link.001HubUse LangSmith '\n",
      " 'Hub to craft, version, and comment on prompts. No\\xa0engineering experience '\n",
      " 'required.002Annotation QueuesTry out LangSmith Annotation Queues to add '\n",
      " 'human labels and feedback on traces.003DatasetsEasily collect examples, and '\n",
      " 'construct datasets from production data or existing sources. Datasets can be '\n",
      " 'used for evaluations, few-shot prompting, and even fine-tuning.004Test & '\n",
      " 'Evaluate: Measure quality over large test suites.Layer in human feedback on '\n",
      " 'runs or use AI-assisted evaluation, with\\xa0off-the-shelf and custom '\n",
      " 'evaluators that can check for relevance,\\xa0correctness, harmfulness, '\n",
      " 'insensitivity, and more.Evaluation\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '001Dataset Construction\\n'\n",
      " '\\n'\n",
      " 'Quickly save debugging and production traces to datasets. Datasets are '\n",
      " 'collections of either exemplary or problematic inputs and outputs that '\n",
      " 'should be replicated or rectified, respectively.002Auto-evaluation\\n'\n",
      " '\\n'\n",
      " 'Use an LLM and prompt to score your application output, or write your own '\n",
      " 'functional evaluation tests to record different measures of '\n",
      " 'effectiveness.003Regression testing\\n'\n",
      " '\\n'\n",
      " 'See how performance of the evaluation criteria that youâ€™ve defined is '\n",
      " 'affected by changes to your application. Know that quality is moving in a '\n",
      " 'positive direction by applying engineering rigor to your testing '\n",
      " 'workflow.004Online evaluation\\n'\n",
      " '\\n'\n",
      " 'Continuously track qualitative characteristics of any live application, and '\n",
      " 'spot issues in real-time with LangSmith monitoring.Add observability to '\n",
      " 'strengthen your applications.Request a demoSign UpOne-click deployEasily '\n",
      " 'deploy your applications with hosted LangServe. Get built in '\n",
      " 'parallelization, fallbacks, batch, streaming, and async support, coupled '\n",
      " 'with familiar LangSmith visibility and a built-in playground.Explore '\n",
      " 'LangServe\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Monitor cost, latency, quality.See whatâ€™s happening with your production '\n",
      " 'application, so you can take action when needed or rest assured while your '\n",
      " 'chains and agents do the hard work.Go to Docs\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'User feedback collection\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Advanced filtering\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Online \\u2028'\n",
      " 'auto-evaluation\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Cost tracking\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Inspect anomalies and errors\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Spot latency spikes\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'User feedback collectionAdvanced filteringOnline \\u2028'\n",
      " 'auto-evaluationCost trackingInspect anomalies and errorsSpot latency spikes\\n'\n",
      " '\\n'\n",
      " 'LangSmith turns LLM \\u2028'\n",
      " '\"magic\"\\xa0into enterprise-ready applications.Got a question?Can I use '\n",
      " 'LangSmith if I donâ€™t use LangChain?\\n'\n",
      " '\\n'\n",
      " 'Yes! Many companies who donâ€™t build with LangChain use LangSmith. You can '\n",
      " 'log traces to LangSmith via the Python SDK, the TypeScript SDK, or the API. '\n",
      " 'See here for more information.I canâ€™t have data leave my environment. Can I '\n",
      " 'self-host LangSmith?\\n'\n",
      " '\\n'\n",
      " 'Yes, we allow customers to self-host LangSmith on our enterprise plan. We '\n",
      " 'deliver the software to run on your Kubernetes cluster, and data will not '\n",
      " 'leave your environment. For more information, check out our '\n",
      " 'documentation.How easy is it to start using LangSmith if I use LangChain?\\n'\n",
      " '\\n'\n",
      " 'Getting started is as easy as setting three environment variables in your '\n",
      " 'LangChain code. When you use the LangSmith SDK, thereâ€™s a callback handler '\n",
      " 'to collect traces and send them to your LangSmith Organization. All your '\n",
      " 'trace steps will be formatted automatically, so thereâ€™s virtually no set up '\n",
      " 'cost.My application isnâ€™t written in Python or TypeScript. Will LangSmith be '\n",
      " 'helpful?\\n'\n",
      " '\\n'\n",
      " 'Yes, we have an API that allows you to programmatically interact with every '\n",
      " 'feature LangSmith has to offer, including logging traces, creating datasets, '\n",
      " 'and running evals. See documentation for more detail.Where is LangSmith data '\n",
      " 'stored?\\n'\n",
      " '\\n'\n",
      " \"Traces are stored in GCP us-central-1. Organizations' traces are logically \"\n",
      " 'separated from each other in a Clickhouse database and encrypted in transit '\n",
      " 'and at rest.What information is contained in LangSmith traces?\\n'\n",
      " '\\n'\n",
      " 'LangSmith traces contain the full information of all the inputs and outputs '\n",
      " 'of each step of the application. This level of information is needed, so '\n",
      " \"that users have full visibility into what's happening in their applications \"\n",
      " 'for debugging purposes.Can I sample the traces that I send to LangSmith?\\n'\n",
      " '\\n'\n",
      " 'Yes, starting with the LangSmith Python SDK version 0.0.84 and JS SDK '\n",
      " 'version 0.0.64, you can specify the % of traces you send to LangSmith. See '\n",
      " 'documentation for more detail.Will LangSmith add latency to my application?\\n'\n",
      " '\\n'\n",
      " 'No, LangSmith does not add any latency to your application. In the LangSmith '\n",
      " 'SDK, thereâ€™s a callback handler that sends traces to a LangSmith trace '\n",
      " 'collector which runs as an async, distributed process. Additionally, if '\n",
      " 'LangSmith experiences an incident, your application performance will not be '\n",
      " 'disrupted.Will you train on the data that I send LangSmith?\\n'\n",
      " '\\n'\n",
      " 'We will not train on your data, and you own all rights to your data. See '\n",
      " 'LangSmith Terms\\xa0of\\xa0Service for more information.How much does '\n",
      " 'LangSmith cost?\\n'\n",
      " '\\n'\n",
      " 'See our pricing page for more information, and find a plan that works for '\n",
      " 'you.Ready to start shipping \\u2028'\n",
      " 'reliable GenAI apps faster?LangChain and LangSmith are critical parts of the '\n",
      " 'reference \\u2028'\n",
      " 'architecture to get you from prototype to production.Request a demoSign '\n",
      " 'UpProductsLangChainLangSmithLangServeAgentsEvaluationRetrievalResourcesPython '\n",
      " 'DocsJS/TS DocsGitHubIntegrationsTemplatesLangChain QuickstartLangChain.js '\n",
      " 'QuickstartCompanyAboutBlogTwitterDiscordLinkedInYouTubeMarketing AssetsSign '\n",
      " 'up for our newsletter to stay up to dateThank you! Your submission has been '\n",
      " 'received!Oops! Something went wrong while submitting the form.All systems '\n",
      " 'operationalPrivacy PolicyTerms of Service\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(doc[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LangSmith es una plataforma unificada de DevOps para desarrollar, colaborar, '\n",
      " 'probar, implementar y monitorear aplicaciones LLM. Ofrece visibilidad '\n",
      " 'completa, colaboraciÃ³n entre desarrolladores y expertos en la materia, '\n",
      " 'evaluaciÃ³n de calidad, despliegue sencillo y monitoreo de costos, latencia y '\n",
      " 'calidad. Es una herramienta esencial para convertir aplicaciones LLM en '\n",
      " 'soluciones empresariales listas para producciÃ³n.')\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "respuesta = llm.predict(\"Â¿Que es LangSmith?, Se breve y ten en cuenta lo siguiente: \" + doc[0].page_content)\n",
    "\n",
    "pprint.pprint(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LangSmith es una plataforma de desarrollo unificada para aplicaciones '\n",
      " 'impulsadas por LLM (Large Language Models). Ofrece herramientas para '\n",
      " 'desarrollar, colaborar, probar, implementar y monitorear aplicaciones LLM, '\n",
      " 'desde la creaciÃ³n de prototipos hasta la producciÃ³n. La plataforma '\n",
      " 'proporciona visibilidad completa en la secuencia de llamadas, depuraciÃ³n en '\n",
      " 'tiempo real, colaboraciÃ³n en equipo, evaluaciÃ³n y monitoreo de aplicaciones '\n",
      " 'LLM.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\")\n",
    "respuesta = llm.predict(\"Â¿Que es LangSmith?, Se breve y ten en cuenta lo siguiente: \" + doc[0].page_content)\n",
    "\n",
    "pprint.pprint(respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/2.png\" width=\"500\" height=\"340\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejoramos el prompt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "TEMPLATE = \"\"\"\\\n",
    "Eres un asistente de IA que respuesta preguntas del usuario sobre LangSmith.\n",
    "Para responder a la pregunta, te proporcionarÃ© un cierto contexto.\n",
    "\n",
    "Debes de ser:\n",
    "- Excesivamente alegre\n",
    "- Muy breve\n",
    "- Muy divertido\n",
    "- Usa puntos para ser esquemÃ¡tico.\n",
    "- Responde en espaÃ±ol\n",
    "\n",
    "\n",
    "Pregunta:\n",
    "{pregunta}\n",
    "\n",
    "Contexto\n",
    "{contexto}\n",
    "\"\"\"\n",
    "\n",
    "template = ChatPromptTemplate.from_template(TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['contexto', 'pregunta'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['contexto', 'pregunta'], template='Eres un asistente de IA que respuesta preguntas del usuario sobre LangSmith.\\nPara responder a la pregunta, te proporcionarÃ© un cierto contexto.\\n\\nDebes de ser:\\n- Excesivamente alegre\\n- Muy breve\\n- Muy divertido\\n- Usa puntos para ser esquemÃ¡tico.\\n- Responde en espaÃ±ol\\n\\n\\nPregunta:\\n{pregunta}\\n\\nContexto\\n{contexto}\\n'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregunta = \"Â¿Que es LangSmith?\"\n",
    "contexto = doc[0].page_content\n",
    "\n",
    "mensaje = template.format(pregunta=pregunta, contexto=contexto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Human: Eres un asistente de IA que respuesta preguntas del usuario sobre '\n",
      " 'LangSmith.\\n'\n",
      " 'Para responder a la pregunta, te proporcionarÃ© un cierto contexto.\\n'\n",
      " '\\n'\n",
      " 'Debes de ser:\\n'\n",
      " '- Excesivamente alegre\\n'\n",
      " '- Muy breve\\n'\n",
      " '- Muy divertido\\n'\n",
      " '- Usa puntos para ser esquemÃ¡tico.\\n'\n",
      " '- Responde en espaÃ±ol\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Pregunta:\\n'\n",
      " 'Â¿Que es LangSmith?\\n'\n",
      " '\\n'\n",
      " 'Contexto\\n'\n",
      " 'LangSmith\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Products\\n'\n",
      " '\\n'\n",
      " 'LangChainLangSmithLangServeMethods\\n'\n",
      " '\\n'\n",
      " 'RetrievalAgentsEvaluationResources\\n'\n",
      " '\\n'\n",
      " 'Developer ResourcesTemplatesIntegrationsLangChain QuickstartLangChain.js '\n",
      " 'QuickstartCompany ResourcesBlogCase StudiesUse Case '\n",
      " 'InspirationPartnersLangSmith Trust PortalDocs\\n'\n",
      " '\\n'\n",
      " 'LangChain DocsLangSmith DocsPricingCompany\\n'\n",
      " '\\n'\n",
      " 'AboutCareersSign UpGet your LLM app from prototype to productionAn '\n",
      " 'all-in-one developer platform for every step of the LLM-powered '\n",
      " 'application\\xa0lifecycle, whether youâ€™re building with LangChain or not.Sign '\n",
      " 'upRequest a demo\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'LangSmith is a unified DevOps platform for developing, collaborating, '\n",
      " 'testing, deploying, and monitoring LLM applications.100K+Users signed up\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '200M+Traces logged\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '20K+Monthly active teams\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'The platform for your LLM development lifecycleLLM-apps are powerful, but '\n",
      " 'have peculiar characteristics. The non-determinism, coupled with '\n",
      " 'unpredictable, natural language inputs, make for countless ways the system '\n",
      " 'can fall short. Traditional engineering best practices need to be '\n",
      " 're-imagined for working with LLMs, and LangSmith supports all phases of the '\n",
      " 'development lifecycle.Sign Up\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Develop with greater visibilityUnexpected results happen all the time with '\n",
      " 'LLMs. With full visibility into the entire sequence of calls, you can spot '\n",
      " 'the source of errors and performance bottlenecks in real-time with surgical '\n",
      " 'precision. Debug. Experiment. Observe. Repeat. Until youâ€™re happy with your '\n",
      " 'results.Go to Docs\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Collaborate with teammates to get app behavior just right.Building '\n",
      " 'LLM-powered applications requires a close partnership between\\xa0developers '\n",
      " 'and subject matter experts.Go to Docs\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'TracesEasily share a chain trace with colleagues, clients, or end users, '\n",
      " 'bringing explainability to anyone with the shared link.001HubUse LangSmith '\n",
      " 'Hub to craft, version, and comment on prompts. No\\xa0engineering experience '\n",
      " 'required.002Annotation QueuesTry out LangSmith Annotation Queues to add '\n",
      " 'human labels and feedback on traces.003DatasetsEasily collect examples, and '\n",
      " 'construct datasets from production data or existing sources. Datasets can be '\n",
      " 'used for evaluations, few-shot prompting, and even fine-tuning.004Test & '\n",
      " 'Evaluate: Measure quality over large test suites.Layer in human feedback on '\n",
      " 'runs or use AI-assisted evaluation, with\\xa0off-the-shelf and custom '\n",
      " 'evaluators that can check for relevance,\\xa0correctness, harmfulness, '\n",
      " 'insensitivity, and more.Evaluation\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '001Dataset Construction\\n'\n",
      " '\\n'\n",
      " 'Quickly save debugging and production traces to datasets. Datasets are '\n",
      " 'collections of either exemplary or problematic inputs and outputs that '\n",
      " 'should be replicated or rectified, respectively.002Auto-evaluation\\n'\n",
      " '\\n'\n",
      " 'Use an LLM and prompt to score your application output, or write your own '\n",
      " 'functional evaluation tests to record different measures of '\n",
      " 'effectiveness.003Regression testing\\n'\n",
      " '\\n'\n",
      " 'See how performance of the evaluation criteria that youâ€™ve defined is '\n",
      " 'affected by changes to your application. Know that quality is moving in a '\n",
      " 'positive direction by applying engineering rigor to your testing '\n",
      " 'workflow.004Online evaluation\\n'\n",
      " '\\n'\n",
      " 'Continuously track qualitative characteristics of any live application, and '\n",
      " 'spot issues in real-time with LangSmith monitoring.Add observability to '\n",
      " 'strengthen your applications.Request a demoSign UpOne-click deployEasily '\n",
      " 'deploy your applications with hosted LangServe. Get built in '\n",
      " 'parallelization, fallbacks, batch, streaming, and async support, coupled '\n",
      " 'with familiar LangSmith visibility and a built-in playground.Explore '\n",
      " 'LangServe\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Monitor cost, latency, quality.See whatâ€™s happening with your production '\n",
      " 'application, so you can take action when needed or rest assured while your '\n",
      " 'chains and agents do the hard work.Go to Docs\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'User feedback collection\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Advanced filtering\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Online \\u2028'\n",
      " 'auto-evaluation\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Cost tracking\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Inspect anomalies and errors\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Spot latency spikes\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'User feedback collectionAdvanced filteringOnline \\u2028'\n",
      " 'auto-evaluationCost trackingInspect anomalies and errorsSpot latency spikes\\n'\n",
      " '\\n'\n",
      " 'LangSmith turns LLM \\u2028'\n",
      " '\"magic\"\\xa0into enterprise-ready applications.Got a question?Can I use '\n",
      " 'LangSmith if I donâ€™t use LangChain?\\n'\n",
      " '\\n'\n",
      " 'Yes! Many companies who donâ€™t build with LangChain use LangSmith. You can '\n",
      " 'log traces to LangSmith via the Python SDK, the TypeScript SDK, or the API. '\n",
      " 'See here for more information.I canâ€™t have data leave my environment. Can I '\n",
      " 'self-host LangSmith?\\n'\n",
      " '\\n'\n",
      " 'Yes, we allow customers to self-host LangSmith on our enterprise plan. We '\n",
      " 'deliver the software to run on your Kubernetes cluster, and data will not '\n",
      " 'leave your environment. For more information, check out our '\n",
      " 'documentation.How easy is it to start using LangSmith if I use LangChain?\\n'\n",
      " '\\n'\n",
      " 'Getting started is as easy as setting three environment variables in your '\n",
      " 'LangChain code. When you use the LangSmith SDK, thereâ€™s a callback handler '\n",
      " 'to collect traces and send them to your LangSmith Organization. All your '\n",
      " 'trace steps will be formatted automatically, so thereâ€™s virtually no set up '\n",
      " 'cost.My application isnâ€™t written in Python or TypeScript. Will LangSmith be '\n",
      " 'helpful?\\n'\n",
      " '\\n'\n",
      " 'Yes, we have an API that allows you to programmatically interact with every '\n",
      " 'feature LangSmith has to offer, including logging traces, creating datasets, '\n",
      " 'and running evals. See documentation for more detail.Where is LangSmith data '\n",
      " 'stored?\\n'\n",
      " '\\n'\n",
      " \"Traces are stored in GCP us-central-1. Organizations' traces are logically \"\n",
      " 'separated from each other in a Clickhouse database and encrypted in transit '\n",
      " 'and at rest.What information is contained in LangSmith traces?\\n'\n",
      " '\\n'\n",
      " 'LangSmith traces contain the full information of all the inputs and outputs '\n",
      " 'of each step of the application. This level of information is needed, so '\n",
      " \"that users have full visibility into what's happening in their applications \"\n",
      " 'for debugging purposes.Can I sample the traces that I send to LangSmith?\\n'\n",
      " '\\n'\n",
      " 'Yes, starting with the LangSmith Python SDK version 0.0.84 and JS SDK '\n",
      " 'version 0.0.64, you can specify the % of traces you send to LangSmith. See '\n",
      " 'documentation for more detail.Will LangSmith add latency to my application?\\n'\n",
      " '\\n'\n",
      " 'No, LangSmith does not add any latency to your application. In the LangSmith '\n",
      " 'SDK, thereâ€™s a callback handler that sends traces to a LangSmith trace '\n",
      " 'collector which runs as an async, distributed process. Additionally, if '\n",
      " 'LangSmith experiences an incident, your application performance will not be '\n",
      " 'disrupted.Will you train on the data that I send LangSmith?\\n'\n",
      " '\\n'\n",
      " 'We will not train on your data, and you own all rights to your data. See '\n",
      " 'LangSmith Terms\\xa0of\\xa0Service for more information.How much does '\n",
      " 'LangSmith cost?\\n'\n",
      " '\\n'\n",
      " 'See our pricing page for more information, and find a plan that works for '\n",
      " 'you.Ready to start shipping \\u2028'\n",
      " 'reliable GenAI apps faster?LangChain and LangSmith are critical parts of the '\n",
      " 'reference \\u2028'\n",
      " 'architecture to get you from prototype to production.Request a demoSign '\n",
      " 'UpProductsLangChainLangSmithLangServeAgentsEvaluationRetrievalResourcesPython '\n",
      " 'DocsJS/TS DocsGitHubIntegrationsTemplatesLangChain QuickstartLangChain.js '\n",
      " 'QuickstartCompanyAboutBlogTwitterDiscordLinkedInYouTubeMarketing AssetsSign '\n",
      " 'up for our newsletter to stay up to dateThank you! Your submission has been '\n",
      " 'received!Oops! Something went wrong while submitting the form.All systems '\n",
      " 'operationalPrivacy PolicyTerms of Service\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(mensaje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Â¡Hola! LangSmith es una plataforma unificada para desarrollar, colaborar, '\n",
      " 'probar, implementar y monitorear aplicaciones LLM. Â¡Es genial! ðŸš€. '\n",
      " 'Â¡RegÃ­strate ahora! ðŸŒŸ. Â¡Explora todas las funciones! ðŸ¤–. Â¡DiviÃ©rtete creando '\n",
      " 'aplicaciones increÃ­bles! ðŸŽ‰.')\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "respuesta = llm.predict(mensaje)\n",
    "\n",
    "pprint.pprint(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Â¡Hola!\\n'\n",
      " '\\n'\n",
      " 'LangSmith es una plataforma de desarrollo unificada para aplicaciones LLM '\n",
      " '(Large Language Models). Â¡Es como una caja de herramientas para '\n",
      " 'desarrolladores que quieren crear aplicaciones poderosas y confiables con '\n",
      " 'LLM!\\n'\n",
      " '\\n'\n",
      " 'â€¢ Desarrolla, colabora, depura, despliega y monitorea tus aplicaciones LLM '\n",
      " 'de principio a fin.\\n'\n",
      " 'â€¢ Ofrece visibilidad total en la secuencia de llamadas, depuraciÃ³n en tiempo '\n",
      " 'real y colaboraciÃ³n en equipo.\\n'\n",
      " 'â€¢ Incluye caracterÃ­sticas como trazas, evaluaciÃ³n, depuraciÃ³n y monitoreo '\n",
      " 'para asegurar la calidad y confiabilidad de tus aplicaciones.\\n'\n",
      " '\\n'\n",
      " 'Â¡Eso es LangSmith en una nutshell!')\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\")\n",
    "respuesta = llm.predict(mensaje)\n",
    "\n",
    "pprint.pprint(respuesta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/3.png\" width=\"500\" height=\"340\"> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
